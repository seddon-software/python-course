{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:red;background-color:black\">\n",
    "Diamond Light Source\n",
    "<br style=\"color:red;background-color:antiquewhite\"><h1>Python Language: Threading</h1>  \n",
    "\n",
    "Â©2000-20 Chris Seddon \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Thread\n",
    "A thread is a separate flow of execution through your code. This means that different threads may be running the same code at different times, but the again they may be executing entirely different code.\n",
    "\n",
    "Threads are used when you want to run multiple sections of code concurrently.  In most programming languages, threads can be run on different CPUs to achieve true concurrency, but often time slicing on the same CPU is used to create apparent concurrency.  When multiple CPUs are used, threading can greatly spped up code.\n",
    "\n",
    "Most Python programs are run using CPython which is the default implementation of Python.  However, CPython is not thread safe.  What this means is that CPython creates a Global Interface Lock (GIL) each time a thread is run, effectively serialising threaded code.\n",
    "\n",
    "In practice, threading is still useful for concurrent tasks, but your code won't necessarily run faster.  IO-bound tasks spend a lot of time waiting for data to be ready.  For these tasks there is a real speed benefit, by switching to running code in another thread, when the the current thread becomes I/O bound.  However, for CPU-bound tasks, switching threads won't speed things up because no threads are waiting.\n",
    "\n",
    "CPython has always been single threaded and it is highly unlikely that this will ever change.  PyPy is the other popular implementation of Python, but that too has a GIL.  The good news is that code that uses C/C++, Numpy or Cython may well support multithreaded CPU-bound tasks.\n",
    "\n",
    "If you want to run concurrent CPU-bound Python code, you should check out the multiprocessing module instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Creating Threads\n",
    "Recall that threads are used to perform concurrent tasks.  Threads are ultimately created by the operating system (kernel), but as far as we are concerned we make a Python call to start a thread; the Python interpreter then contacts the kernel.\n",
    "\n",
    "Python provides a helper class to manage threads.  Rather confusingly, this class is called \"Thread\".  Objects of this class are NOT threads, just helper objects!\n",
    "\n",
    "All programs start with a single thread (often called the main thread).  When the main thread wants to create further threads, it creates objects of the helper class and calls their \"start\" method:<pre>thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()</pre>\n",
    "\n",
    "Realize that when the new threads start, they need to perform a different task (or function) from the main thread.  This task is specified as a parameter when the main thread creates the helper objects:<pre>thread1 = Thread(target=myfunc, args=(\"1\",))\n",
    "thread2 = Thread(target=myfunc, args=(\"2\",))\n",
    "thread3 = Thread(target=myfunc, args=(\"3\",))</pre>\n",
    "Creating the helper objects DOES NOT create any threads - calling the start method creates and starts a thread.\n",
    "\n",
    "After the \"start\" method has been called, execution of the main thread and the other threads continues in parallel.  Because the operating system may suspend threads at any time, it is not possible to predict which order code will execute unless we use special synchronization objects.\n",
    "\n",
    "In this example the main thread creates 3 other threads which all execute the \"myfunc\" function.  Each of these threads terminate when they exit this function.  I've added some random timings to emphasize the parallel nature of this program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from threading import Thread\n",
    "\n",
    "def myfunc(name):\n",
    "    for i in range (1, 50):\n",
    "        sys.stdout.write(name)        \n",
    "        time.sleep(random.random() * 0.1)      \n",
    "\n",
    "# define a callback function - to be called via start()\n",
    "thread1 = Thread(target=myfunc, args=(\"1\",))\n",
    "thread2 = Thread(target=myfunc, args=(\"2\",))\n",
    "thread3 = Thread(target=myfunc, args=(\"3\",))\n",
    "\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()\n",
    "\n",
    "print(\"\\nEnd of main Thread\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Joining Threads\n",
    "Note that the main thread is counted a just another thread (it is not special).  However, often programs are designed such that the main thread is the last to complete.  To achieve this, the main thread can wait for the other threads to complete before proceding:<pre>thread1.join()\n",
    "thread2.join()\n",
    "thread3.join()</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from threading import Thread\n",
    "\n",
    "def myfunc(name):\n",
    "    for i in range (1, 50):\n",
    "        sys.stdout.write(name)        \n",
    "        time.sleep(random.random() * 0.1)      \n",
    "\n",
    "# define a callback function - to be called via start()\n",
    "thread1 = Thread(target=myfunc, args=(\"1\",))\n",
    "thread2 = Thread(target=myfunc, args=(\"2\",))\n",
    "thread3 = Thread(target=myfunc, args=(\"3\",))\n",
    "\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()\n",
    "\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "thread3.join()\n",
    "\n",
    "print(\"\\nEnd of main Thread\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Using Methods as Callbacks\n",
    "As an alternative, we can make the callback function a method in a class; this ultimately depends on operator overloading.  \n",
    "\n",
    "In the previous example the callback function was \"myfunc\" and after the \"start\" method is called, Python calls this function:<pre>myfunc()</pre>\n",
    "\n",
    "Thus Python hits the function pointer with the function call operator:<pre>( )</pre>\n",
    "\n",
    "Beacause of operator overloading, it is possible to define an object as a callback:<pre>t1 = Thread(target = m1, args = (\"1\",))\n",
    "t2 = Thread(target = m2, args = (\"2\",))\n",
    "t3 = Thread(target = m3, args = (\"3\",))</pre>\n",
    "\n",
    "and then Python will callback with:<pre>m1()\n",
    "m2()\n",
    "m3()</pre>\n",
    "\n",
    "Now the function call operator \"()\" is implemented as the \"\\__call__\" method:<pre>    def \\__call__(self, name): ...</pre>\n",
    "\n",
    "So we can use an object as a callback on the understanding that the object's \"\\__call__\" method will be the callback function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "# create a callable class\n",
    "class MyClass:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, name):\n",
    "        for i in range (1, 50):\n",
    "            sys.stdout.write(name)        \n",
    "            time.sleep(random.random() * 0.1)    \n",
    "\n",
    "    \n",
    "m1 = MyClass()\n",
    "m2 = MyClass()\n",
    "m3 = MyClass()\n",
    "\n",
    "# define a callback class - __call__() to be called via start()\n",
    "t1 = Thread(target = m1, args = (\"1\",))\n",
    "t2 = Thread(target = m2, args = (\"2\",))\n",
    "t3 = Thread(target = m3, args = (\"3\",))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n",
    "\n",
    "print(\"\\nEnd of main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Locks\n",
    "To control parallel threads we can use synchronization classes.  The most import is the \"Lock\" class.\n",
    "\n",
    "A \"Lock\" object or lock will allow only one thread at a time execute code.  A thread acquires a lock with:<pre>lock.acquire()</pre>\n",
    "and releases a lock with <pre>lock.release()</pre>\n",
    "\n",
    "These locks are often called monitor locks; they monitor code and only allow one thread at a time execute code between the \"acquire\" and \"release\" calls.\n",
    "\n",
    "In this example, 4 threads execute code in the \"\\__call__\" method, but the monitor lock serializes execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread, Lock\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "# task for threads\n",
    "def task(name, lock):\n",
    "    lock.acquire()        \n",
    "    for i in range (1, 50):\n",
    "        sys.stdout.write(name)\n",
    "        time.sleep(random.random() * 0.1)\n",
    "    lock.release()    \n",
    "\n",
    "    \n",
    "lock = Lock()\n",
    "\n",
    "t1 = Thread(target = task, args = (\"1\", lock))\n",
    "t2 = Thread(target = task, args = (\"2\", lock))\n",
    "t3 = Thread(target = task, args = (\"3\", lock))\n",
    "t4 = Thread(target = task, args = (\"4\", lock))\n",
    "\n",
    "# create 4 threads\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "t4.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Locks\n",
    "If we modify the example slightly and create 2 locks, one lock shared by threads 1 and 3 and the other by threads 2 and 4 then the locks will prevent 1 and 3 running simultaneously and similarly with 2 and 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread, Lock\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "# task for threads\n",
    "def task(name, lock):\n",
    "    lock.acquire()        \n",
    "    for i in range (1, 50):\n",
    "        sys.stdout.write(name)\n",
    "        time.sleep(random.random() * 0.1)\n",
    "    lock.release()    \n",
    "\n",
    "    \n",
    "lockA = Lock()\n",
    "lockB = Lock()\n",
    "\n",
    "t1 = Thread(target = task, args = (\"1\", lockA))\n",
    "t2 = Thread(target = task, args = (\"2\", lockB))\n",
    "t3 = Thread(target = task, args = (\"3\", lockA))\n",
    "t4 = Thread(target = task, args = (\"4\", lockB))\n",
    "\n",
    "# create 4 threads\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "t4.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Data Contention\n",
    "Locks can also be used to protect data.  In the program below we create 3 threads.  The threads increment two counters in a loop.  Note that access to \"count1\" is unprotected, but \"count2\" is protected by a lock.  \n",
    "\n",
    "As we will see below, when a thread executes the instruction:<pre>count1 += 1</pre> it is possible that the kernel will suspend the thread in the middle of the instruction.  This can easily result in data corruption.  Before we investigate, let's run the program.  Each count gets incremented 6,000,000 times, but what are he final values of these counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from threading import Lock\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# 3 threads increment 2 counts ...\n",
    "# count1 is unprotected\n",
    "# count2 is protected\n",
    "\n",
    "class MyClass:\n",
    "    def __call__(self, name):\n",
    "        global lock, count1, count2\n",
    "        for i in range(0, 2*1000*1000):\n",
    "            count1 += 1\n",
    "            lock.acquire()\n",
    "            count2 += 1\n",
    "            lock.release()\n",
    "\n",
    "    \n",
    "lock = Lock()\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "\n",
    "m1 = MyClass()\n",
    "m2 = MyClass()\n",
    "m3 = MyClass()\n",
    "\n",
    "t1 = Thread(target = m1, args = (\"1\",))\n",
    "t2 = Thread(target = m2, args = (\"2\",))\n",
    "t3 = Thread(target = m3, args = (\"3\",))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n",
    "\n",
    "print(f\"count1: {count1}\")\n",
    "print(f\"count2: {count2}\")\n",
    "\n",
    "print(\"\\nEnd of main\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Data Corruption\n",
    "The data corruption occurs because:<pre>\n",
    "    count1 += 1</pre>\n",
    "is not an atomic operation.  We can see this by examining the byte code using the disassembler module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dis\n",
    "dis.dis(\"x += 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Atomic Instructions\n",
    "What can happen is that the thread can get suspended by the kernel just after the INPLACE_ADD instruction.  \n",
    "\n",
    "Suppose \"x\" is some value, say 700.  Inside the interpreter, the INPLACE_ADD will add 1 to 700 and store 701 in a machine register.  If the thread then gets suspended, this register will be cached by the kernel.  \n",
    "\n",
    "Other threads will now increment \"x\" many times.  Let's say \"x\" ends up with the value 3287 for sake of argument.\n",
    "\n",
    "Eventually, the original thread will be restarted.  Its registers will be reinstated by the kernel, so it can continue where it left off.  The thread was just about to execute the STORE_NAME instruction; when it does execute the instruction it uses the value 701 from the reinstated register.  This overwrites 3287 with 701, thereby corrupting the count.  That's what happened above.\n",
    "\n",
    "Conclusion: all non-atomic operations need protecting by locks.\n",
    "\n",
    "But how do we know if an operation is atomic?  Take a look at the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dis\n",
    "dis.dis(\"[2,5,3,6].sort()\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Condition Variables\n",
    "In the above, the \"sort\" method is executed as a single byte code instruction CALL_METHOD.  This is what makes it atomic.  The Python interpreter cannot suspend a thread part way through a byte code instruction.\n",
    "\n",
    "The instruction:<pre>count1 += 1</pre>was several byte code instructions and therefore was non-atomic.\n",
    "\n",
    "This all occurs despite the GIL.  The Python interpreter creates a Global Interpreter Lock (GIL) for the thread, but it releases the lock every 15 msec, but not during an atomic operation.\n",
    "\n",
    "So operations consisting of a single byte code are thread safe.\n",
    "\n",
    "Apart from locks, there are some other synchronization primatives to consider.  Let's now look at the producer/consumer code below.  The problem we have here is that the producer will create data for each of the consumers, but it might take some time to do so.  It is important that the consumers don't attempt to use the data before it is available.\n",
    "\n",
    "We can use a \"condition\" variable to synchronize the threads:<pre>dataAvailable = threading.Condition()</pre>\n",
    "The consumers all wait on the \"condition\" variable:<pre>dataAvailable.wait()</pre>\n",
    "until the producer is ready to provide the data.  The producer notifies all the consumers that they can proceed with:<pre>dataAvailable.notifyAll()</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from threading import Thread\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "class Producer:\n",
    "    def __call__(self, dataAvailable):\n",
    "        print(\"Producer is obtaining data\")\n",
    "        time.sleep(5)\n",
    "        with dataAvailable:         # grab the lock\n",
    "            print(\"Producer is notifying all consumers\")\n",
    "            dataAvailable.notifyAll()\n",
    "\n",
    "class Consumer:\n",
    "    def __call__(self, name, dataAvailable):\n",
    "        with dataAvailable:\n",
    "            print(f\"consumer{name} is waiting\")\n",
    "            dataAvailable.wait()\n",
    "            print(f\"consumer{name} is has obtained the data\")\n",
    "\n",
    "    \n",
    "dataAvailable = threading.Condition()\n",
    "\n",
    "producer = Producer()\n",
    "consumer1 = Consumer()\n",
    "consumer2 = Consumer()\n",
    "consumer3 = Consumer()\n",
    "\n",
    "# give each thread a lock\n",
    "t = Thread(target = producer, args = (dataAvailable,))\n",
    "t1 = Thread(target = consumer1, args = (\"1\", dataAvailable))\n",
    "t2 = Thread(target = consumer2, args = (\"2\", dataAvailable))\n",
    "t3 = Thread(target = consumer3, args = (\"3\", dataAvailable))\n",
    "\n",
    "t.start()\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "\n",
    "t.join()\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n",
    "\n",
    "print(\"\\nEnd of main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Events\n",
    "Event objects are very similar to condition variables.  \n",
    "\n",
    "The event object is created by:<pre>event = Event()</pre>\n",
    "and any thread can wait on the event:<pre>event.wait()</pre>\n",
    "All waiting threads are released when any thread \"sets\" the event:<pre>event.set()</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from threading import Event\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "class MyClass:\n",
    "    def __call__(self, name):\n",
    "        global event\n",
    "        print(f\"{name} waiting for event\");\n",
    "        event.wait()\n",
    "        print(f\"\\t{name} proceeding after event\");\n",
    "\n",
    "\n",
    "event = Event()\n",
    "\n",
    "m1 = MyClass()\n",
    "m2 = MyClass()\n",
    "m3 = MyClass()\n",
    "\n",
    "t1 = Thread(target = m1, args = (\"1\",))\n",
    "t2 = Thread(target = m2, args = (\"2\",))\n",
    "t3 = Thread(target = m3, args = (\"3\",))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "\n",
    "print(\"... main waiting for 15 seconds\")\n",
    "time.sleep(15)\n",
    "print(\"... main clearing event flag\")\n",
    "event.set()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n",
    "\n",
    "print(\"\\nEnd of main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 Bounded Semaphores\n",
    "Bounded semaphores are like a set of multiple locks.  \n",
    "\n",
    "A bounded semaphore is created with an initial count:<pre>semaphore = BoundedSemaphore(3)</pre>\n",
    "\n",
    "Threads can acquire the semaphore by decrementing the count:<pre>semaphore.acquire()</pre>\n",
    "However the count can never go negative.  So after 3 threads have acquired the semaphore the next thread will be blocked until another thread releases the semaphore and increments the count by one<pre>semaphore.release()</pre>\n",
    "This continues until all the threads have acquired and released the semaphore.\n",
    "\n",
    "Thus this bounded semaphore behave as a set of 3 locks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from threading import BoundedSemaphore\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "class MyClass:\n",
    "    def __call__(self, name):\n",
    "        global semaphore\n",
    "        semaphore.acquire()\n",
    "        print((name + \" claimed semaphore\"));\n",
    "        time.sleep(5)\n",
    "        print((\"\\t\" + name + \" released semaphore\"));\n",
    "        semaphore.release()\n",
    "\n",
    "\n",
    "\n",
    "semaphore = BoundedSemaphore(3)\n",
    "\n",
    "m1 = MyClass()\n",
    "m2 = MyClass()\n",
    "m3 = MyClass()\n",
    "m4 = MyClass()\n",
    "m5 = MyClass()\n",
    "m6 = MyClass()\n",
    "m7 = MyClass()\n",
    "\n",
    "t1 = Thread(target = m1, args = (\"1\",))\n",
    "t2 = Thread(target = m2, args = (\"2\",))\n",
    "t3 = Thread(target = m3, args = (\"3\",))\n",
    "t4 = Thread(target = m4, args = (\"4\",))\n",
    "t5 = Thread(target = m5, args = (\"5\",))\n",
    "t6 = Thread(target = m6, args = (\"6\",))\n",
    "t7 = Thread(target = m7, args = (\"7\",))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "t4.start()\n",
    "t5.start()\n",
    "t6.start()\n",
    "t7.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n",
    "t4.join()\n",
    "t5.join()\n",
    "t6.join()\n",
    "t7.join()\n",
    "\n",
    "print(\"\\nEnd of main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 Barriers\n",
    "Barriers are yet another synchronization object.  \n",
    "\n",
    "A barrier is created with a count and a timeout:<pre>b = Barrier(5, timeout=10)</pre>\n",
    "\n",
    "In this example a server and 4 clients synchronize by waiting on this barrier in their respective threads:<pre>b.wait()</pre>\n",
    "When all five threads are waiting, the barrier is satisfied and the Python interpreter removes the barrier and all 5 threads continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread, Barrier\n",
    "import time\n",
    "\n",
    "\n",
    "# In this example a server a 4 clients synchronize by waiting on a barrier\n",
    "# in their respective threads.  When all five threads are waiting, \n",
    "# the barrier is removed and all 5 threads continue.\n",
    "\n",
    "b = Barrier(5, timeout=10)\n",
    "\n",
    "class Server:\n",
    "    def __init__(self):\n",
    "        print(\"server initializing ...\")\n",
    "        self.thread = Thread(target=self)\n",
    "        self.thread.start()\n",
    "\n",
    "    def __call__(self):\n",
    "        time.sleep(5)\n",
    "        b.wait()\n",
    "        print(\"server ready to accept connections\")\n",
    "        \n",
    "    def connect(self, client):\n",
    "        print(f\"{client.name} has connected\")\n",
    "        \n",
    "class Client:\n",
    "    def __init__(self, name, server):\n",
    "        self.name = name\n",
    "        self.server = server\n",
    "        print(f\"{self.name} waiting to connect\")\n",
    "        self.thread = Thread(target=self)\n",
    "        self.thread.start()\n",
    "    \n",
    "    def __call__(self):\n",
    "        b.wait()\n",
    "        self.server.connect(self)\n",
    "\n",
    "def main():\n",
    "    server = Server()\n",
    "    client1 = Client(\"client1\", server)\n",
    "    client2 = Client(\"client2\", server)\n",
    "    client3 = Client(\"client3\", server)\n",
    "    client4 = Client(\"client4\", server)\n",
    "    \n",
    "    server.thread.join()\n",
    "    client1.thread.join()\n",
    "    client2.thread.join()\n",
    "    client3.thread.join()\n",
    "    client4.thread.join()\n",
    "    \n",
    "    print(\"end of program\")\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13 Timers\n",
    "I should mention the simple Timer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Timer\n",
    "\n",
    "def hello():\n",
    "    print(\"hello, world\")\n",
    "\n",
    "t = Timer(15.0, hello)\n",
    "t.start() # after 15 seconds, \"hello, world\" will be printed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14 Benchmarking\n",
    "Finally, as mentioned in the introduction to this tutorial, with multi threaded CPU-bound programs, the threads are executed sequentially because of the GIL.  Performance then becomes an issue.\n",
    "\n",
    "It is recommended to use the multiprocessing module to speed thing up in such situations.  We don't use threads in this case, but execute code in separate processes such that the GIL is irrelevant.\n",
    "\n",
    "It will be interesting to compare a multthreaded program with a mutiprocessing program for timings.  Both programs calculate the value of  \n",
    "\n",
    "$$\\sum i^{0.3}$$  \n",
    "where i ranges from 0 to 50,000,000.  We can see the performance of both with varying numbers of threads and processes (don't worry to much about the code details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os\n",
    "from threading import Thread\n",
    "from multiprocessing import Process, Pool\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "\n",
    "''' Calculate the sum of i**0.3 where i ranges from 0 to M\n",
    "    Use multiple threads or processes to perform the calculation\n",
    "    Split the calculation into ranges using the intervals function below\n",
    "'''\n",
    "\n",
    "M = 50*1000*1000\n",
    "\n",
    "def calculate(lo, hi):\n",
    "    '''the calculation to perform'''\n",
    "    sum = 0\n",
    "    for i in range (lo, hi):\n",
    "        sum += float(i)**0.3\n",
    "    return sum   \n",
    "\n",
    "def intervals(duration, parts):\n",
    "    '''splits an interval into several(part) ranges'''\n",
    "    part_duration = int(duration / parts)\n",
    "    return [(int(i * part_duration), int((i + 1) * part_duration)) for i in range(parts)]\n",
    "\n",
    "# calculate the sum using multiple threads\n",
    "def jobUsingThreads(threadCount):\n",
    "    threadList = []\n",
    "    it = intervals(M, threadCount)\n",
    "    \n",
    "    for i in range(threadCount):\n",
    "        t = Thread(target = calculate, args = it[i])\n",
    "        t.start()\n",
    "        threadList.append(t)\n",
    "        \n",
    "    for t in threadList:\n",
    "        t.join()\n",
    "\n",
    "# calculate the sum using multiple threads\n",
    "def jobUsingProcesses(processCount):\n",
    "    p = Pool(processes=processCount)\n",
    "    it = intervals(M, processCount)\n",
    "    result = p.starmap(calculate, it)\n",
    "\n",
    "# run job with varying number of processes\n",
    "for N in chain(range(1, 11), range(20, 101, 20)):\n",
    "    start = time.perf_counter()\n",
    "    jobUsingProcesses(N)\n",
    "    finish = time.perf_counter()\n",
    "    print(f\"{N:2} processes:{finish-start:6.2f}\")\n",
    "\n",
    "# run job with varying number of processes\n",
    "for N in chain(range(1, 11), range(20, 101, 20)):\n",
    "    start = time.perf_counter()\n",
    "    jobUsingThreads(N)\n",
    "    finish = time.perf_counter()\n",
    "    print(f\"{N:2} threads:{finish-start:6.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
